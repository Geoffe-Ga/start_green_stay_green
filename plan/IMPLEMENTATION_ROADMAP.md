# Start Green Stay Green - Implementation Roadmap

**Last Updated:** 2026-01-16
**Status:** Active Development
**Current Phase:** Phase 1 (Quality Foundation)

---

## Table of Contents

- [Overview](#overview)
- [Current Status](#current-status)
- [Critical Path Analysis](#critical-path-analysis)
- [Implementation Phases](#implementation-phases)
  - [Phase 1: Quality Foundation](#phase-1-quality-foundation-weeks-1-2)
  - [Phase 2: Content Generators](#phase-2-content-generators-weeks-3-4)
  - [Phase 3: CLI & Integration](#phase-3-cli--integration-weeks-5-6)
  - [Phase 4: Polish & Documentation](#phase-4-polish--documentation-week-7)
- [Issue Dependency Graph](#issue-dependency-graph)
- [Risk Management](#risk-management)
- [Success Metrics](#success-metrics)

---

## Overview

This document outlines the strategic approach to completing the Start Green Stay Green project. The roadmap is organized into 4 phases, each building on the previous phase's deliverables.

**Project Goal:** Build a meta-tool that generates quality-controlled, AI-ready repositories with enterprise-grade quality controls pre-configured.

**Philosophy:** Maximum Quality Engineering - ship green on all checks with zero outstanding issues.

---

## Current Status

### ‚úÖ Completed Work

- **Core AI Infrastructure**
  - ‚úÖ AIOrchestrator implemented with retry logic
  - ‚úÖ Prompt management system
  - ‚úÖ Token usage tracking
  - ‚úÖ Error handling and validation
  - ‚úÖ Claude Code Review workflow (issues #36, #37, #81, #82)

- **Quality Infrastructure**
  - ‚úÖ Complete pre-commit hooks
  - ‚úÖ CI pipeline with all checks
  - ‚úÖ Scripts for formatting, linting, testing
  - ‚úÖ Coverage tracking (97%+)
  - ‚úÖ Security scanning (bandit, safety, detect-secrets)

- **Project Foundation**
  - ‚úÖ Repository structure
  - ‚úÖ Python package configuration
  - ‚úÖ Development environment
  - ‚úÖ CLAUDE.md project context

### üîÑ Current Work

- **Issue #62**: Mutation testing coverage (49% ‚Üí 80%)
  - Currently at 49.04% (437/891 mutants killed)
  - Need to kill 276 more mutants
  - Main blocker: `precommit.py` (335 survivors), `ci.py` (72 survivors)

### üìã Remaining Work

- **15 open issues** across 4 epics
  - 5 P0-critical issues
  - 7 P1-high issues
  - 2 P2-medium issues
  - 1 P3-low issue (implicitly from mutation testing)

---

## Critical Path Analysis

The critical path determines the minimum time to project completion. Here's the dependency chain:

```
Issue #62 (Mutation Testing)
    ‚Üì
Issue #22 (Copy SGSG Assets) [P0-CRITICAL]
    ‚Üì
Issue #9 (Tuning System) [P1-HIGH]
    ‚Üì
‚îú‚îÄ‚îÄ Issue #13 (Skills Generator) [P1-HIGH]
‚îÇ       ‚Üì
‚îÇ   Issue #23 (Missing Skills) [P1-HIGH]
‚îÇ
‚îî‚îÄ‚îÄ Issue #14 (Subagents Generator) [P1-HIGH]
        ‚Üì
    Issue #24 (Dependency Checker) [P1-HIGH]
        ‚Üì
    Issue #15 (CLAUDE.md Generator) [P0-CRITICAL]
        ‚Üì
    Issue #19 (CLI Framework) [P0-CRITICAL]
        ‚Üì
    Issue #20 (Init Command) [P0-CRITICAL]
        ‚Üì
    ‚îú‚îÄ‚îÄ Issue #25 (Unit Tests) [P0-CRITICAL]
    ‚îú‚îÄ‚îÄ Issue #26 (Integration Tests) [P1-HIGH]
    ‚îú‚îÄ‚îÄ Issue #21 (GitHub Integration) [P1-HIGH]
    ‚îî‚îÄ‚îÄ Issue #27 (README) [P0-CRITICAL]
            ‚Üì
        ‚îú‚îÄ‚îÄ Issue #16 (GitHub Actions Review) [P1-HIGH]
        ‚îú‚îÄ‚îÄ Issue #18 (Architecture Enforcement) [P1-HIGH]
        ‚îú‚îÄ‚îÄ Issue #17 (Metrics Dashboard) [P2-MEDIUM]
        ‚îî‚îÄ‚îÄ Issue #28 (API Docs) [P2-MEDIUM]
```

**Critical Path Duration:** ~7 weeks (assuming 1 issue per day for complex issues)

---

## Implementation Phases

### Phase 1: Quality Foundation (Weeks 1-2)

**Goal:** Establish unshakeable quality baseline that enables fast, confident development.

**Why First:** Can't build on a broken foundation. Mutation testing ensures our test suite actually catches bugs.

#### Week 1: Mutation Testing Blitz

**Issue #62: Improve Mutation Test Coverage (80% threshold)**

**Current:** 49.04% (437/891 killed)
**Target:** 80%+ (713/891 killed)
**Gap:** 276 mutants to kill

**Attack Plan:**

1. **Day 1-3: Fix `precommit.py` (335 survivors ‚Üí 135 survivors)**
   - **Target:** Kill 200 mutants in precommit.py
   - **Approach:**
     ```bash
     # Identify survivors by line
     mutmut results | grep precommit.py

     # For each surviving mutant
     mutmut show <id>  # See what mutant survived
     # Write targeted test to kill it

     # Focus areas (from issue):
     - Lines 443-886: Hook configuration generation
     - Language-specific hooks (Python, TypeScript, Go, etc.)
     - Edge cases in validation logic
     ```
   - **Tactics:**
     - Property-based testing with Hypothesis for config generation
     - Boundary value tests for all conditional logic
     - Error path coverage for validation methods
     - Test each language's hook configuration independently

2. **Day 4-5: Fix `ci.py` (72 survivors ‚Üí 22 survivors)**
   - **Target:** Kill 50 mutants in ci.py
   - **Approach:**
     - Test all validation methods thoroughly
     - Test YAML generation edge cases
     - Test error messages and exception paths
     - Add assertion tests for exact output format

3. **Day 6: Fix remaining files (46 survivors ‚Üí 16 survivors)**
   - **Files:**
     - `prompts/manager.py`: 13 survivors
     - `orchestrator.py`: 4 survivors (3 + 1 suspicious)
     - `base.py`: 1 survivor
   - **Approach:** Targeted mutation-killer tests

4. **Day 7: CI Enforcement & Buffer**
   - Update CI workflow to enforce 80% threshold
   - Remove "Skipping mutation score validation" logic
   - Handle any edge cases discovered during testing
   - **Buffer:** Account for harder-than-expected mutants

**Success Criteria:**
- [ ] Mutation score ‚â• 80%
- [ ] CI enforces threshold (fail on <80%)
- [ ] All tests pass in < 5 minutes
- [ ] Mutation testing completes in < 2 hours

#### Week 2: Reference Assets Foundation

**Issue #22: Copy Existing Start Green Stay Green Assets** (2 days)

**Goal:** Establish the reference library that generators will use.

**Execution:**
```bash
# Create reference structure
mkdir -p reference/{ci,scripts,skills,subagents,precommit,claude}

# Copy from ../specinit (v1) - use discernment
cp ../specinit/MAXIMUM_QUALITY_ENGINEERING.md reference/
cp -r ../specinit/.github/workflows reference/ci/
cp -r ../specinit/scripts reference/scripts/
# ... (see issue #22 for complete list)

# Validate all references
./scripts/test.sh tests/unit/reference/
```

**Success Criteria:**
- [ ] All reference files copied and organized
- [ ] Files validated (no broken references)
- [ ] Directory structure matches spec
- [ ] Unit tests for reference file loading

**Issue #23: Create Missing Skills** (3 days)

**Skills to Create:**
1. **vibe.md** - Coding style and tone
   - Code as prose
   - Self-documenting names
   - Minimal comments
   - Anti-patterns

2. **concurrency.md** - Async/threading patterns
   - Python asyncio patterns
   - TypeScript Promises
   - Go goroutines
   - Rust async/await
   - Anti-patterns (callback hell, race conditions)

**Success Criteria:**
- [ ] Both skills documented
- [ ] Consistent format with existing skills
- [ ] Language-specific examples
- [ ] Anti-patterns section

**Issue #24: Create Dependency Checker Subagent** (2 days)

**Checks to Implement:**
- Package source trust verification
- Recent activity check
- Download count validation
- CVE vulnerability scan
- License compatibility
- Package size reasonableness
- Install script inspection
- Transitive dependency review

**Response Format:**
```
APPROVED: <package> - all checks pass
REJECTED: <package> - <reason with evidence>
REVIEW_NEEDED: <package> - <concerns>
```

**Success Criteria:**
- [ ] All 8 mandatory checks documented
- [ ] Response format specified
- [ ] Examples included
- [ ] Integration with CI documented

---

### Phase 2: Content Generators (Weeks 3-4)

**Goal:** Implement the AI-powered generation system that creates quality infrastructure.

**Why Now:** Foundation is solid (80% mutation coverage, reference assets ready).

#### Week 3: AI Generation Infrastructure

**Issue #9: Tuning Pass System** (2 days)

**Implementation:**
```python
class ContentTuner:
    """Lightweight Sonnet-based content adaptation."""

    async def tune(
        self,
        source_content: str,
        source_context: str,
        target_context: str,
        preserve_sections: list[str] | None = None,
    ) -> TuningResult:
        """Adapt content from source to target context."""
        # Use Sonnet (cost-efficient)
        # Preserve structure
        # Log changes
        # Validate output
```

**Success Criteria:**
- [ ] Tuner implemented with Sonnet
- [ ] Preserves markdown structure
- [ ] Logs all changes made
- [ ] Dry-run mode available
- [ ] 90%+ test coverage

**Issue #13: Skills Generator** (2 days)

**Flow:**
1. Load skills from `reference/skills/`
2. Use ContentTuner to adapt to target project
3. Validate structure preserved
4. Output to target project's `.claude/skills/`

**Success Criteria:**
- [ ] Copies all skills from reference
- [ ] Adapts content via tuner
- [ ] Preserves skill structure
- [ ] Validates output
- [ ] Tests with mocked tuner

**Issue #14: Subagents Generator** (3 days)

**Required Subagents:**
- chief-architect.md (coordinator)
- quality-reviewer.md
- test-generator.md
- security-auditor.md
- dependency-checker.md (NEW)
- documentation.md
- refactorer.md
- performance.md

**Flow:**
1. Load subagents from `reference/subagents/`
2. Tune via ContentTuner
3. Include dependency checker
4. Validate chief-architect allocation logic

**Success Criteria:**
- [ ] All 8 subagents generated
- [ ] Dependency checker included
- [ ] Chief-architect coordination logic
- [ ] Validated structure

#### Week 4: Core Generators

**Issue #15: CLAUDE.md Generator** (3 days)

**Critical Implementation:**
```python
class CLAUDEMDGenerator:
    def generate(self, project_config: ProjectConfig) -> str:
        """Generate CLAUDE.md for target project."""
        # Inject MAXIMUM_QUALITY_ENGINEERING.md
        # Inject SGSG CLAUDE.md as reference
        # Customize for project commands
        # Document generated scripts
        # Document generated skills
        # Validate markdown structure
```

**Success Criteria:**
- [ ] Incorporates MQE framework
- [ ] References SGSG CLAUDE.md
- [ ] Project-specific commands
- [ ] Script documentation
- [ ] Skill documentation
- [ ] Validated structure

**Parallel Work (Can be done concurrently):**

**Issue #18: Architecture Enforcement Generator** (2 days)
- Generate `.importlinter` for Python
- Generate `.dependency-cruiser.js` for TypeScript
- Output to `/plans/architecture/`
- Usage instructions in README

**Issue #17: Quality Metrics Dashboard** (2 days)
- Configure 10 metrics from MQE Part 9.1
- Generate SonarQube config
- Generate GitHub badges
- Dashboard template (HTML/React)

---

### Phase 3: CLI & Integration (Weeks 5-6)

**Goal:** Make the tool usable with a polished CLI and GitHub integration.

#### Week 5: CLI Implementation

**Issue #19: CLI Framework Setup** (2 days)

**Commands:**
```bash
green --help
green version
green init [options]
green generate [component]
green validate
green github [subcommand]
```

**Tech Stack:**
- Typer for CLI
- Rich for output formatting
- Pydantic for config validation

**Success Criteria:**
- [ ] All commands implemented
- [ ] Help text clear and complete
- [ ] Version command working
- [ ] Config file support
- [ ] Verbose/quiet modes

**Issue #20: Init Command** (4 days)

**Interactive Flow:**
```
$ green init

üöÄ Welcome to Start Green Stay Green

? Project name: my-awesome-project
? Primary language: Python
? Framework: FastAPI
? Include TypeScript frontend? Yes
? Frontend framework: React
? GitHub repository? Yes
? Create GitHub issues? Yes
? Enable AI code review? Yes

üìã Configuration Summary:
   [display config]

? Proceed? Yes

‚è≥ Generating components...
[progress bars for each step]

‚úÖ Success! Next steps:
   cd my-awesome-project
   ./scripts/setup-dev.sh
   git push -u origin main
```

**Components to Generate:**
1. CI pipeline
2. Pre-commit config
3. Quality scripts
4. Skills
5. Subagents
6. CLAUDE.md
7. GitHub Actions (optional)
8. Metrics dashboard (optional)
9. Architecture rules (optional)
10. Git initialization

**Success Criteria:**
- [ ] Interactive prompts working
- [ ] Non-interactive mode with config file
- [ ] Progress indicators
- [ ] Clear error messages
- [ ] Dry-run mode
- [ ] Git initialization
- [ ] All generators orchestrated

**Issue #25: Unit Tests for Generators** (2 days)

**Test Coverage:**
- Each generator in `tests/unit/generators/`
- Mock AI responses
- Test valid output
- Test error handling
- Test edge cases
- 90%+ coverage

#### Week 6: GitHub Integration

**Issue #21: GitHub Integration** (3 days)

**Features:**
```bash
green github auth           # Configure token
green github create-repo    # Create repository
green github create-issues  # Parse SPEC.md ‚Üí issues
green github setup-all      # Full setup
```

**Issue Generation:**
- Parse SPEC.md (or generated SPEC.md)
- Create GitHub issues with:
  - Title from Issue header
  - Body from Description + Acceptance Criteria
  - Labels from Type/Priority
  - Milestone from Epic
  - Estimate as label

**Success Criteria:**
- [ ] Repository creation via API
- [ ] Branch protection config
- [ ] Issue creation from SPEC.md
- [ ] Epic/milestone creation
- [ ] Labels setup
- [ ] Secure token management

**Issue #16: GitHub Actions Code Review** (2 days)

**OPTIONAL Feature** (requires Claude Code)

**Workflow:**
1. Triggers on PR open/update
2. Uses Claude API for review
3. Strict response format
4. Categorizes issues (Low/Medium/High/Critical)
5. Auto-creates GitHub issues for Low
6. Blocks merge for Medium+

**Success Criteria:**
- [ ] Made optional in init flow
- [ ] Workflow generates correctly
- [ ] Response format enforced
- [ ] Issue categorization working
- [ ] Documentation explains Claude Code requirement

**Issue #26: Integration Tests** (2 days)

**Test Scenarios:**
1. Full init flow (mocked AI)
2. GitHub integration (mocked API)
3. Generated output validity
4. Generated scripts execute
5. Generated CI syntax valid

**Success Criteria:**
- [ ] E2E tests in `tests/integration/`
- [ ] All generation flows tested
- [ ] Generated artifacts validated
- [ ] Scripts executable
- [ ] CI configs valid

---

### Phase 4: Polish & Documentation (Week 7)

**Goal:** Ship-ready product with excellent documentation.

#### Week 7: Documentation & Final Polish

**Issue #27: README Documentation** (2 days)

**Sections:**
1. Project Overview
2. Installation
   - PyPI: `pip install start-green-stay-green`
   - From source: `git clone && pip install -e .`
3. Quick Start Guide
   - `green init`
   - Example walkthrough
4. Full Command Reference
   - All CLI commands documented
   - All options explained
5. Configuration Options
   - Config file format
   - All settings explained
6. Examples
   - Python FastAPI project
   - TypeScript React project
   - Multi-language project
7. Contributing Guidelines
   - Development setup
   - Testing requirements
   - PR process
8. License (MIT)

**Success Criteria:**
- [ ] All 8 sections complete
- [ ] Clear and concise
- [ ] Examples tested
- [ ] Screenshots/GIFs for CLI
- [ ] Links validated

**Issue #28: API Documentation** (2 days)

**Tools:**
- pdoc for Python API docs
- Sphinx for comprehensive docs

**Content:**
- All public APIs documented
- Examples in docstrings
- Generated HTML docs
- Deployment to GitHub Pages or ReadTheDocs

**Success Criteria:**
- [ ] pdoc configuration
- [ ] All public modules documented
- [ ] Examples in docstrings
- [ ] HTML docs generated
- [ ] Docs deployed

**Final Testing & Polish** (3 days)

1. **Full E2E Test**
   - Generate a real project
   - Run all generated scripts
   - Push to GitHub
   - Verify all checks pass
   - Test AI code review (if enabled)

2. **Performance Testing**
   - Time full generation flow
   - Optimize slow generators
   - Target: < 2 minutes for basic project

3. **Error Handling Review**
   - Test all error paths
   - Ensure clear error messages
   - Add recovery suggestions

4. **Final Quality Checks**
   - Run `./scripts/check-all.sh`
   - Run `./scripts/mutation.sh`
   - Verify 80%+ mutation score maintained
   - Fix any issues

5. **Release Prep**
   - Version bump to 1.0.0
   - Changelog generation
   - Release notes
   - PyPI packaging

---

## Issue Dependency Graph

### Visualization

```
                                    Issue #62 (Mutation Testing)
                                              |
                                              v
                                    Issue #22 (Copy Assets) [P0]
                                              |
                                              v
                                    Issue #9 (Tuning System)
                                              |
                        +---------------------+---------------------+
                        |                                           |
                        v                                           v
              Issue #13 (Skills)                          Issue #14 (Subagents)
                        |                                           |
                        v                                           v
              Issue #23 (Missing Skills)                Issue #24 (Dep Checker)
                        |                                           |
                        +---------------------+---------------------+
                                              |
                                              v
                                    Issue #15 (CLAUDE.md) [P0]
                                              |
                                              v
                                    Issue #19 (CLI Framework) [P0]
                                              |
                                              v
                                    Issue #20 (Init Command) [P0]
                                              |
            +----------------+----------------+----------------+----------------+
            |                |                |                |                |
            v                v                v                v                v
    Issue #25 (Tests) Issue #21 (GitHub) Issue #27 (README) Issue #18 (Arch) Issue #17 (Metrics)
         [P0]            [P1]            [P0]            [P1]            [P2]
            |                |                |                |                |
            +----------------+----------------+----------------+----------------+
                                              |
                        +---------------------+---------------------+
                        |                                           |
                        v                                           v
              Issue #26 (Integration)                     Issue #16 (GH Actions)
                    [P1]                                         [P1]
                        |                                           |
                        +---------------------+---------------------+
                                              |
                                              v
                                    Issue #28 (API Docs) [P2]
                                              |
                                              v
                                         üéâ SHIP üéâ
```

### Parallel Work Opportunities

These issues can be worked on simultaneously:

**Phase 1:**
- Issue #22, #23, #24 (all independent after #62)

**Phase 2:**
- Issue #13, #14 (both depend on #9, but independent of each other)
- Issue #17, #18 (can start after #15)

**Phase 3:**
- Issue #21, #25, #26 (all can start after #20)
- Issue #16 (can start after #21)

**Phase 4:**
- Issue #27, #28 (independent)

**Parallelization Factor:** With 2 developers, could reduce timeline by ~30%.

---

## Risk Management

### High-Risk Items

#### 1. Mutation Testing (Issue #62)

**Risk:** Killing 276 mutants might take longer than 1 week.

**Impact:** Blocks all other work.

**Mitigation:**
- Start immediately
- Focus on high-value survivors first (precommit.py, ci.py)
- Use property-based testing with Hypothesis
- If stuck at 75% by day 5, reduce threshold to 75% temporarily
- Create follow-up issue for remaining 5%

**Contingency:** Reduce threshold to 75% for initial ship, create issue #63 for 80%.

#### 2. AI Token Costs

**Risk:** Extensive use of Claude API during development could be expensive.

**Impact:** Development costs.

**Mitigation:**
- Use Sonnet for tuning (cheaper than Opus)
- Cache AI responses in tests
- Use mock responses in unit tests
- Monitor token usage closely
- Set budget alerts

**Contingency:** Use more templates, less AI generation for MVP.

#### 3. GitHub Integration Complexity

**Risk:** GitHub API edge cases and authentication complexities.

**Impact:** Delays in Phase 3.

**Mitigation:**
- Study PyGithub library thoroughly
- Test with personal repos first
- Handle rate limiting gracefully
- Provide manual fallback instructions

**Contingency:** Make GitHub integration optional for MVP.

#### 4. Time Estimates

**Risk:** Issues might take longer than estimated.

**Impact:** Schedule slip.

**Mitigation:**
- 20% buffer built into each phase
- Prioritize P0/P1 issues
- P2 issues can be deferred to 1.1 release
- Track velocity after Phase 1

**Contingency:** Defer P2 issues (#17, #28) to v1.1.

### Medium-Risk Items

#### 5. Content Generation Quality

**Risk:** AI-generated content might not meet quality standards.

**Impact:** Need more refinement loops.

**Mitigation:**
- Extensive validation in generators
- Human review of generated samples
- Comprehensive test suite
- Tuning system for refinement

**Contingency:** Fall back to template-based generation with variables.

#### 6. Cross-Platform Compatibility

**Risk:** Scripts might not work on Windows.

**Impact:** Reduced user base.

**Mitigation:**
- Use pathlib for paths
- Test on Windows via GitHub Actions
- Provide PowerShell alternatives

**Contingency:** Document as "Linux/macOS only" for MVP, Windows in v1.1.

---

## Success Metrics

### MVP (v1.0.0) Release Criteria

**Quality Metrics:**
- [ ] Test coverage ‚â• 90%
- [ ] Mutation score ‚â• 80%
- [ ] Pylint score ‚â• 9.0
- [ ] All pre-commit hooks pass
- [ ] Zero security vulnerabilities
- [ ] Documentation coverage ‚â• 95%

**Feature Completeness:**
- [ ] All P0 issues closed (#15, #19, #20, #22, #25, #27)
- [ ] All P1 issues closed (#9, #13, #14, #16, #21, #23, #24, #26, #62)
- [ ] P2 issues optional (#17, #28)

**User Experience:**
- [ ] `green init` works end-to-end
- [ ] Generated project passes all checks
- [ ] Documentation complete and clear
- [ ] Error messages helpful
- [ ] Examples tested and working

**Performance:**
- [ ] Full generation < 2 minutes (basic project)
- [ ] Full generation < 5 minutes (complex project)
- [ ] Token usage optimized (< $1 per generation)

**Deployment:**
- [ ] Published to PyPI
- [ ] GitHub releases configured
- [ ] Changelog complete
- [ ] License clear (MIT)

### Post-MVP (v1.1.0+)

**Features:**
- Additional language support (Java, C#, Ruby)
- Web UI for configuration
- Project templates library
- Metrics dashboard UI
- CI/CD integrations (GitLab, Bitbucket)

---

## Timeline Summary

| Phase | Duration | Completion Date | Key Deliverables |
|-------|----------|-----------------|------------------|
| **Phase 1: Quality Foundation** | 2 weeks | Week 2 | 80% mutation coverage, reference assets |
| **Phase 2: Content Generators** | 2 weeks | Week 4 | All generators working, AI tuning system |
| **Phase 3: CLI & Integration** | 2 weeks | Week 6 | `green init` working, GitHub integration |
| **Phase 4: Polish & Docs** | 1 week | Week 7 | README, API docs, release prep |
| **TOTAL** | **7 weeks** | **Week 7** | **v1.0.0 ready to ship** |

**Buffer:** 20% built into each phase (1-2 days per phase)

**Parallel Work:** With 2 developers, could reduce to ~5 weeks

**Aggressive Timeline:** With sacrificing P2 issues, could ship in 6 weeks

---

## Next Steps

### Immediate Actions (This Week)

1. **Start Issue #62: Mutation Testing Blitz**
   ```bash
   # Identify top survivors
   mutmut results | grep precommit.py | head -20

   # Attack highest-impact survivors first
   mutmut show <id>
   # Write test
   pytest tests/unit/generators/test_precommit.py -v
   ```

2. **Set up tracking**
   ```bash
   # Create project board
   gh project create --title "Start Green Stay Green - MVP"

   # Add all issues to board
   gh issue list --state open --json number \
     | jq -r '.[].number' \
     | xargs -I {} gh issue edit {} --add-project "Start Green Stay Green - MVP"
   ```

3. **Daily standup format**
   - What did I complete yesterday?
   - What am I working on today?
   - Any blockers?
   - Mutation score update

### Week 1 Goals

- [ ] Mutation score ‚â• 60% by end of day 3
- [ ] Mutation score ‚â• 75% by end of day 5
- [ ] Mutation score ‚â• 80% by end of day 7
- [ ] CI enforcement in place

### Communication

- **Daily:** Update mutation score in issue #62
- **Weekly:** Update this roadmap with progress
- **Blockers:** Flag immediately with [BLOCKED] in issue title

---

## Appendix: Issue Quick Reference

| Issue | Title | Priority | Estimate | Dependencies |
|-------|-------|----------|----------|--------------|
| #62 | Mutation Testing 80% | P1-high | 1 week | None |
| #22 | Copy SGSG Assets | P0-critical | 2 days | #62 |
| #9 | Tuning Pass System | P1-high | 2 days | #22 |
| #13 | Skills Generator | P1-high | 2 days | #9 |
| #23 | Missing Skills | P1-high | 3 days | #13 |
| #14 | Subagents Generator | P1-high | 3 days | #9 |
| #24 | Dependency Checker | P1-high | 2 days | #14 |
| #15 | CLAUDE.md Generator | P0-critical | 3 days | #14, #24 |
| #19 | CLI Framework | P0-critical | 2 days | #15 |
| #20 | Init Command | P0-critical | 4 days | #19 |
| #25 | Unit Tests Generators | P0-critical | 2 days | #20 |
| #21 | GitHub Integration | P1-high | 3 days | #20 |
| #27 | README | P0-critical | 2 days | #20 |
| #26 | Integration Tests | P1-high | 2 days | #25 |
| #16 | GitHub Actions Review | P1-high | 2 days | #21 |
| #18 | Architecture Enforcement | P1-high | 2 days | #15 |
| #17 | Metrics Dashboard | P2-medium | 2 days | #15 |
| #28 | API Documentation | P2-medium | 2 days | #27 |

**Total Estimated Time:** 41 days of work
**With Parallelization:** ~30 days (7 weeks with 20% buffer)

---

**End of Roadmap**

_This is a living document. Update as issues are completed and new information emerges._
